{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "26e994cd",
      "metadata": {
        "id": "26e994cd"
      },
      "source": [
        "# รายวิชา: ข้อมูลขนาดใหญ่ (Big Data)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/witsarutsarai12-Academic/128-356-Big-Data/blob/main/BigData_Week1_Slides_in_Jupyter.ipynb)\n",
        "\n",
        " สัปดาห์ที่ 1: บทนำ + Python พื้นฐานสำหรับ Data Science\n",
        "\n",
        "\n",
        "Notebook นี้ออกแบบให้ใช้สอนแบบ **สไลด์ใน Jupyter** (ข้อความอ่านได้ + โค้ดทดลอง) โดยแบ่งเป็นช่วงย่อย\n",
        "- Part 0 เตรียมสภาพแวดล้อม\n",
        "- Part 1 แนะนำผู้สอน\n",
        "- Part 2 แนะนำรายวิชาและภาพรวมการประเมิน\n",
        "- Part 3 Big Data คืออะไร\n",
        "- Part 3.1 พัฒนาการทางประวัติศาสตร์ของ Big Data\n",
        "- Part 4 ทำไม Python คือภาษาหลักของงานข้อมูล\n",
        "- Part 5 Python พื้นฐาน (Hands-on)\n",
        "- Part 6 Python สำหรับ Data Science\n",
        "- Part 7 สรุปท้ายคาบ\n",
        "\n",
        "___\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc676269",
      "metadata": {
        "id": "fc676269"
      },
      "source": [
        "## Part 0: การเตรียมสภาพแวดล้อม\n",
        "\n",
        "การเตรียมสภาพแวดล้อม (Environment Setup) เป็นก้าวแรกที่สำคัญของนักข้อมูล การตรวจสอบเวอร์ชันของเครื่องมือช่วยลดปัญหาความเข้ากันได้ (Compatibility Issues) ที่อาจเกิดขึ้นเมื่อทำงานร่วมกับทีม หรือเมื่อนำโค้ดไปรันในเครื่องอื่น\n",
        "\n",
        "**Checklist สั้น ๆ ก่อนเริ่ม**\n",
        "- ใช้ `python --version` และ `pip list | head` ตรวจสอบว่าเวอร์ชันตรงกับที่ระบุในคอร์ส (>= 3.9)\n",
        "- หากใช้ Colab ให้รัน block ตรวจสอบไลบรารีก่อนทุกครั้ง เพราะ environment ถูกรีเซตทุก session\n",
        "- ถ้าเครื่องส่วนตัวติดตั้งแพ็กเกจไม่ได้ แนะนำสร้าง virtual environment (venv/conda) เพื่อแยก dependency ของวิชานี้ออกจากโปรเจ็กต์อื่น"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c39ddf97",
      "metadata": {
        "id": "c39ddf97"
      },
      "outputs": [],
      "source": [
        "# ตรวจสอบเวอร์ชัน Python\n",
        "import sys\n",
        "sys.version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d63673",
      "metadata": {
        "id": "20d63673"
      },
      "outputs": [],
      "source": [
        "# ตรวจสอบไลบรารีหลัก\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(np.__version__, pd.__version__)iuyfytfh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5686f14",
      "metadata": {
        "id": "a5686f14"
      },
      "source": [
        "## Part 1: แนะนำผู้สอน\n",
        "\n",
        "### ผู้สอนรายวิชา\n",
        "- ชื่อ–สกุล: วิศรุต สาหร่าย\n",
        "- บทบาทและประสบการณ์:\n",
        "  - Data Engineer / Data Scientist - US Startup\n",
        "  - งานระบบข้อมูลขนาดใหญ่ (Data Pipeline / Cloud / Spark)\n",
        "  - งานวิเคราะห์ข้อมูลเชิงธุรกิจและการนำเสนอผลลัพธ์\n",
        "\n",
        "**เป้าหมายการเรียนรู้ร่วมกัน**\n",
        "- สร้างความเข้าใจเชิงโครงสร้าง ไม่ใช่แค่การใช้เครื่องมือ\n",
        "- ฝึกทำงานข้อมูลแบบทำซ้ำได้ (reproducible) และอธิบายได้ (explainable)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d0a4da9",
      "metadata": {
        "id": "6d0a4da9"
      },
      "source": [
        "## Part 2: แนะนำรายวิชาและ Syllabus\n",
        "\n",
        "### รายวิชานี้เรียนอะไรบ้าง\n",
        "ในรายวิชานี้ เราจะเน้นสร้างความเข้าใจพื้นฐานที่แข็งแรง เพื่อให้นักศึกษาสามารถต่อยอดไปยังเครื่องมือระดับสูงได้\n",
        "- Big Data คืออะไร (ในโลกจริง) และทำไมเราถึงต้องสนใจ\n",
        "- Data Pipeline: ingest → clean → transform → analyze (หัวใจของการทำงานข้อมูล)\n",
        "- เครื่องมือที่ใช้จริงในอุตสาหกรรม และแนวโน้มเทคโนโลยีล่าสุด\n",
        "\n",
        "### รูปแบบการเรียน\n",
        "- Lecture + Hands-on ใน Jupyter Notebook\n",
        "- เน้นการคิดเชิงระบบและการทำงานกับข้อมูลขนาดใหญ่กว่าเครื่องมือทั่วไป\n",
        "\n",
        "### การประเมิน (ตัวอย่างโครงสร้าง)\n",
        "- Final Project (เลือกความยากได้): ทำ pipeline กับข้อมูลขนาดใหญ่และทำ dashboard\n",
        "- สอบกลางภาค / ปลายภาค: เน้นความเข้าใจแนวคิดและการอธิบายเหตุผล\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b9718f2",
      "metadata": {
        "id": "3b9718f2"
      },
      "source": [
        "## Part 3: Big Data คืออะไร\n",
        "\n",
        "> **วัตถุประสงค์ของช่วงนี้**: ให้นักศึกษาสามารถนิยาม Big Data ได้อย่างถูกต้องในเชิงระบบ แยกแยะจากคำศัพท์ที่เกี่ยวข้อง และเข้าใจ “เหตุผล” ที่ทำให้ต้องมีเครื่องมือ Big Data รวมถึงเห็นภาพว่าข้อมูลในโลกความเป็นจริงนั้นมีความซับซ้อนเพียงใด\n",
        "\n",
        "### พื้นฐานก่อน Big Data: ข้อมูล (Data) vs สารสนเทศ (Information)\n",
        "ก่อนจะไปถึง \"Big\" Data เรามาทำความเข้าใจรากศัพท์กันก่อน:\n",
        "\n",
        "- **Data (ข้อมูล)**: มาจากภาษาลาตินคำว่า *datum* (เอกพจน์) แปลว่า \"สิ่งที่ให้มา\" (something given)\n",
        "    - คือข้อเท็จจริงดิบ (Raw facts) ตัวเลข ตัวอักษร ที่ยังไม่ผ่านการประมวลผล\n",
        "    - *Example*: 25, \"Male\", 170cm\n",
        "    \n",
        "- **Information (สารสนเทศ)**:\n",
        "    - คือข้อมูลที่ผ่านการประมวลผล (Processed Data) เรียบเรียง หรือจัดกลุ่มแล้ว\n",
        "    - มีบริบท (Context) และความหมาย (Meaning) ที่นำไปใช้ตัดสินใจได้\n",
        "    - *Example*: \"ค่าเฉลี่ยความสูงของนักเรียนชายในห้องคือ 170cm\"\n",
        "\n",
        "> **Wisdom Hierarchy (DIKW Pyramid)**:\n",
        "> Data -> Information -> Knowledge -> Wisdom\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**มุมมองจากผู้เชี่ยวชาญ (Definitions)**\n",
        "- **Gartner (2001)**: \"Big Data is high-volume, high-velocity and/or high-variety information assets that demand cost-effective, innovative forms of information processing.\"\n",
        "\n",
        "\n",
        "***เน้นที่ 3Vs (Volume, Velocity, Variety) เป็นนิยามคลาสสิก***\n",
        "\n",
        "\n",
        "- **Oracle**: \"Big Data is the derivation of value from traditional relational database driven business decision making, augmented with new sources of unstructured data.\"\n",
        "\n",
        "\n",
        "***เน้นที่ \"Value\" - ข้อมูลจะมีค่าก็ต่อเมื่อนำมาใช้ประโยชน์ได้***\n",
        "\n",
        "\n",
        "- **Wikipedia**: \"Big Data consists of extensive datasets primarily in the characteristics of volume, variety, speed, and/or variability that require a scalable architecture for efficient storage, manipulation, and analysis.\" (เน้น Architecture)\n",
        "\n",
        "\n",
        "***เน้นที่ \"ความซับซ้อน\" จนซอฟต์แวร์ประมวลผลข้อมูลแบบเดิม (Standard Data Processing Software) รับมือไม่ได้***\n",
        "\n",
        "\n",
        "> ### **สรุป** Big Data คือข้อมูลหลากหลายมหาศาลที่ไหลเร็วและซับซ้อนจนเกินเครื่องมือเดิม ต้องพึ่งสถาปัตยกรรม/เทคโนโลยีใหม่ที่ขยายได้ และจะมีคุณค่าก็ต่อเมื่อถูกแปลงเป็นมูลค่าทางธุรกิจ.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eea2baa3",
      "metadata": {
        "id": "eea2baa3"
      },
      "source": [
        "### ปัญหาข้อมูลในโลกจริง (Reality of Data)\n",
        "\n",
        "ในโลกจริง ข้อมูลไม่ได้ถูกสร้างเพื่อการวิเคราะห์ แต่เกิดจากกิจกรรมและระบบงาน เช่น การซื้อขาย การใช้งานแอป การสื่อสาร และอุปกรณ์ IoT\n",
        "\n",
        "**ลักษณะของข้อมูลจริง**\n",
        "- เกิดขึ้นตลอดเวลา และเพิ่มขึ้นอย่างต่อเนื่อง (Continuous Growth)\n",
        "- มีหลายรูปแบบ (Structured, Semi-structured, Unstructured) เช่น ตัวเลข ข้อความ ภาพ เสียง พิกัด\n",
        "- มีความผิดพลาด ขาดหาย ซ้ำซ้อน และมี noise (Dirty Data) ซึ่งต้องอาศัยการทำความสะอาดก่อนนำไปใช้\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![messy_vs_clean_data](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/messy_vs_clean_data_1768465020694.png?raw=1)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b479f973",
      "metadata": {
        "id": "b479f973"
      },
      "source": [
        "### นิยาม Big Data (Definition as a System Constraint)\n",
        "\n",
        "Big Data คือชุดข้อมูลหรือภาระงาน (workload) ที่มี **ขนาด ความเร็ว ความหลากหลาย หรือความไม่แน่นอน** สูงจนทำให้การจัดการด้วยเครื่องมือดั้งเดิมไม่เพียงพอ\n",
        "\n",
        "**ประเด็นสำคัญ**\n",
        "- Big Data ไม่ได้หมายถึง “ไฟล์ใหญ่” อย่างเดียว\n",
        "- Big Data คือ **ข้อจำกัดของระบบเดิม** เมื่อเจอข้อมูลจริง\n",
        "\n",
        "> กล่าวอีกนัยหนึ่ง: Big Data คือ “ปัญหา” มากกว่า “เทคโนโลยี”\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb83d5e2",
      "metadata": {
        "id": "fb83d5e2"
      },
      "source": [
        "### ข้อจำกัดของเครื่องมือดั้งเดิม (Why Excel / Single DB Fail)\n",
        "\n",
        "เครื่องมือดั้งเดิมมักทำงานบนเครื่องเดียว (single machine) จึงติดข้อจำกัดเชิงฟิสิกส์\n",
        "\n",
        "**ข้อจำกัดที่พบได้จริง**\n",
        "เมื่อปริมาณข้อมูลเกินขีดจำกัดของ Hardware เครื่องเดียว เราจะเจอปัญหา:\n",
        "- หน่วยความจำ (RAM) ไม่พอ → เปิดไฟล์ไม่ได้ Program Crash หรือทำงานช้ามาก\n",
        "- CPU ไม่พอ → การคำนวณที่ซับซ้อนใช้เวลานานเกินไป (เช่น เป็นวันหรือสัปดาห์)\n",
        "- I/O (อ่าน/เขียน) เป็นคอขวด → การอ่านไฟล์ขนาดใหญ่กินเวลานาน\n",
        "- การทำงานพร้อมกันหลายคน (Concurrency) ทำได้ยากและเสี่ยงต่อข้อมูลเสียหาย\n",
        "\n",
        "**ตัวอย่างสถานการณ์**\n",
        "- ไฟล์ CSV ขนาด 5–20GB: เปิดไม่ได้ในเครื่องทั่วไป\n",
        "- การ Join ข้อมูลหลายตารางขนาดใหญ่: ใช้เวลานานมาก\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15e3559e",
      "metadata": {
        "id": "15e3559e"
      },
      "source": [
        "### 5Vs ของ Big Data (มองให้เป็น “ปัญหา”)\n",
        "\n",
        "การใช้ 5Vs ไม่ใช่เพื่อท่องจำ แต่เพื่อ “จำแนกชนิดของปัญหา”\n",
        "\n",
        "- **Volume**: ปริมาณข้อมูลมหาศาล จนเกินขีดจำกัดการเก็บและประมวลผลของเครื่องเดียว\n",
        "- **Velocity**: ความเร็วของข้อมูลที่เข้ามาอย่างต่อเนื่อง เช่น ข้อมูลจาก Sensor หรือ Social Media ที่ต้องการการประมวลผลแบบ Real-time\n",
        "- **Variety**: ความหลากหลายของรูปแบบข้อมูล ทั้ง Structured (SQL), Semi-structured (JSON, XML), และ Unstructured (Image, Video, Text)\n",
        "- **Veracity**: ความถูกต้องและความน่าเชื่อถือของข้อมูล ซึ่งข้อมูล Big Data มักมีความไม่แน่นอนสูง\n",
        "- **Value**: คุณค่าที่ซ่อนอยู่ ข้อมูลจะมีประโยชน์ก็ต่อเมื่อเราสามารถสกัด Insight ออกมาตัดสินใจได้จริง\n",
        "\n",
        "**ช่วงถาม–คิด**\n",
        "- ปัญหาที่ทำให้ระบบล่มบ่อยที่สุดอยู่ใน V ใด และเพราะอะไร\n",
        "\n",
        "\n",
        "![big_data_5vs](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/big_data_5vs_1768464556575.png?raw=1)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c847f8f",
      "metadata": {
        "id": "9c847f8f"
      },
      "source": [
        "### Big Data vs Traditional Data (เปรียบเทียบเชิงสถาปัตยกรรม)\n",
        "\n",
        "| มิติ | Traditional Data | Big Data |\n",
        "|---|---|---|\n",
        "| ขนาด | MB–GB | TB–PB หรือมากกว่า |\n",
        "| การประมวลผล | Batch รายงานย้อนหลัง | Batch + Streaming + Interactive |\n",
        "| สถาปัตยกรรม | Single-node | Distributed / Cluster |\n",
        "| การขยาย | Vertical scaling | Horizontal scaling |\n",
        "| รูปแบบข้อมูล | ส่วนใหญ่ Structured | Structured + Semi + Unstructured |\n",
        "\n",
        "**สรุป**\n",
        "Big Data ไม่ได้เปลี่ยน “เป้าหมาย” ของการวิเคราะห์ แต่เปลี่ยน “วิธี” ที่ต้องทำเพื่อให้ระบบรองรับได้\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e2e8ac1",
      "metadata": {
        "id": "5e2e8ac1"
      },
      "source": [
        "### ตัวอย่างเชิงกรณีศึกษา (E-commerce / Platform)\n",
        "\n",
        "สมมติแพลตฟอร์มมี:\n",
        "- ผู้ใช้งาน 500,000 คน/วัน\n",
        "- Event log เฉลี่ย 50 events/คน/วัน → 25,000,000 events/วัน\n",
        "- ข้อมูลคำสั่งซื้อ 200,000 รายการ/วัน\n",
        "- ข้อมูลข้อความรีวิวและรูปภาพสินค้า\n",
        "\n",
        "**คำถามที่องค์กรต้องตอบ**\n",
        "- รายได้วันนี้เทียบกับสัปดาห์ก่อนเป็นอย่างไร\n",
        "- สินค้าชนิดใดถูกคืนสูงผิดปกติ\n",
        "- แคมเปญโฆษณาทำให้ conversion ดีขึ้นจริงหรือไม่\n",
        "\n",
        "**ช่วงถาม–คิด**\n",
        "- หากต้องได้คำตอบภายใน 5 นาที ระบบควรออกแบบแบบใด\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a58e4d9",
      "metadata": {
        "id": "8a58e4d9"
      },
      "source": [
        "### Big Data กับบทบาทในองค์กร (Why it matters)\n",
        "\n",
        "Big Data สำคัญเพราะช่วยให้เกิดการตัดสินใจที่:\n",
        "- เร็วขึ้น (timely)\n",
        "- แม่นยำขึ้น (better evidence)\n",
        "- รองรับสถานการณ์ซับซ้อน (complexity)\n",
        "\n",
        "**ตัวอย่างผลลัพธ์ที่จับต้องได้**\n",
        "- ลดต้นทุนการปฏิบัติการ (optimize logistics)\n",
        "- เพิ่มรายได้ (recommendation / targeting)\n",
        "- ลดความเสี่ยง (fraud detection)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672cd498",
      "metadata": {
        "id": "672cd498"
      },
      "source": [
        "### ทำไมต้องมี Data Pipeline (From Raw to Usable)\n",
        "\n",
        "ข้อมูลดิบ (Raw data) ไม่สามารถใช้วิเคราะห์ได้ทันที ต้องผ่านกระบวนการ\n",
        "\n",
        "**Pipeline ขั้นพื้นฐาน**\n",
        "1) **Ingest**: นำเข้าข้อมูลจากแหล่งต่างๆ (Database, API, Logs)\n",
        "2) **Clean**: ทำความสะอาดข้อมูล จัดการค่าที่หายไป (Null) หรือค่าที่ผิดปกติ (Outliers)\n",
        "3) **Transform**: แปลงรูปแบบข้อมูลให้พร้อมใช้ เช่น เปลี่ยนรูปแบบวันที่, รวมตาราง\n",
        "4) **Store**: จัดเก็บลงระบบที่เหมาะสม (Data Warehouse, Data Lake)\n",
        "5) **Analyze**: วิเคราะห์หา Insight หรือนำไปสร้าง Model\n",
        "\n",
        "**ตัวอย่างง่าย**\n",
        "- CSV → แปลงเป็น Parquet → อ่านเร็วขึ้น → วิเคราะห์ได้ไวขึ้น\n",
        "\n",
        "\n",
        "![data_pipeline_flow](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/data_pipeline_flow_1768464591379.png?raw=1)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc34c9b7",
      "metadata": {
        "id": "bc34c9b7"
      },
      "source": [
        "### สรุปนิยามที่ถูกต้อง (Key Takeaways)\n",
        "\n",
        "- Big Data คือ “ปัญหาเชิงระบบ” ที่เกิดจากข้อจำกัดของเครื่องมือดั้งเดิม\n",
        "- เทคโนโลยี Big Data เกิดขึ้นเพื่อแก้ปัญหา 5Vs\n",
        "- เป้าหมายของรายวิชาคือให้ทำ Pipeline ได้จริงและเข้าใจโครงสร้างระบบ\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "240275a5",
      "metadata": {
        "id": "240275a5"
      },
      "source": [
        "## Part 3.1: พัฒนาการทางประวัติศาสตร์ของ Big Data\n",
        "\n",
        "> วัตถุประสงค์: เห็นวิวัฒนาการของ “การจัดการข้อมูล” ตั้งแต่ฐานข้อมูลในองค์กร → ERP/SAP → web-scale → NoSQL → Data Lake/Lakehouse\n",
        "\n",
        "![evolution_timeline](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/evolution_timeline_1768464611899.png?raw=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76e44d69",
      "metadata": {
        "id": "76e44d69"
      },
      "source": [
        "### File-based Systems (ยุคข้อมูลกระจัดกระจาย)\n",
        "\n",
        "- องค์กรจำนวนมากเริ่มจากการเก็บข้อมูลเป็นไฟล์ (CSV, Excel, Text)\n",
        "- ข้อดี: เริ่มง่าย ต้นทุนต่ำ\n",
        "- ข้อจำกัด: ซ้ำซ้อนสูง, เวอร์ชันไม่ตรงกัน, เชื่อมโยงข้อมูลยาก, ควบคุมคุณภาพยาก\n",
        "\n",
        "---\n",
        "\n",
        "![File-based System Visual](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/file_primary_storage.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4479549c",
      "metadata": {
        "id": "4479549c"
      },
      "source": [
        "### ฐานข้อมูล (Database) เกิดขึ้นเพื่ออะไร\n",
        "\n",
        "แนวคิดฐานข้อมูลเกิดขึ้นเพื่อแก้ปัญหาไฟล์กระจัดกระจาย โดยทำให้ข้อมูล\n",
        "- มีศูนย์กลาง (Centralized) ทำให้บริหารจัดการง่าย\n",
        "- มีมาตรฐานและตรวจสอบได้ (Data Integrity)\n",
        "- รองรับผู้ใช้หลายคนพร้อมกัน (Concurrency Control)\n",
        "\n",
        "องค์ประกอบสำคัญที่ทำให้ Database ต่างจากไฟล์:\n",
        "- การกำหนดโครงสร้างข้อมูล (schema)\n",
        "- ดัชนี (index) เพื่อค้นหาเร็ว\n",
        "- การควบคุมสิทธิ์และการทำงานพร้อมกัน (concurrency)\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71d0eb95",
      "metadata": {
        "id": "71d0eb95"
      },
      "source": [
        "### Relational Database (RDBMS) และ SQL\n",
        "\n",
        "- จัดข้อมูลเป็นตาราง + ความสัมพันธ์ระหว่างตาราง\n",
        "- ใช้ SQL ในการสืบค้นและสรุปข้อมูล\n",
        "- จุดแข็ง: ความถูกต้อง (ACID), ความสัมพันธ์ชัดเจน, ใช้ได้ดีมากกับงานธุรกรรม (OLTP)\n",
        "\n",
        "ข้อจำกัด:\n",
        "- เมื่อข้อมูลโตมาก/ผู้ใช้มาก การขยายระบบมีต้นทุนสูง และมักติดปัญหา scale แบบเครื่องเดียว\n",
        "\n",
        "---\n",
        "\n",
        "![RDBMS Visual](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/popular_rdbms.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c9f8271",
      "metadata": {
        "id": "1c9f8271"
      },
      "source": [
        "### สิ่งที่ RDBMS ทำได้ดี และสิ่งที่เริ่มเป็นข้อจำกัด\n",
        "\n",
        "**RDBMS ทำได้ดี**\n",
        "- ข้อมูลธุรกรรม: การเงิน การสั่งซื้อ การลงทะเบียน\n",
        "- ความถูกต้องและการบันทึกประวัติ\n",
        "\n",
        "**ข้อจำกัดที่เริ่มชัดเมื่อข้อมูลโต**\n",
        "- งานวิเคราะห์ที่ต้อง scan จำนวนมากทำให้ช้า\n",
        "- ข้อมูลนอกตาราง (ข้อความ/ภาพ/log) เก็บและใช้งานยาก\n",
        "- ขยายระบบแบบแนวนอนทำได้ยากกว่าแบบไฟล์/ระบบกระจาย\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e715bbf",
      "metadata": {
        "id": "9e715bbf"
      },
      "source": [
        "### ยุคข้อมูลธุรกิจ — ERP (Business Process Data)\n",
        "\n",
        "ก่อนคำว่า Big Data จะเป็นที่นิยม องค์กรธุรกิจมี “ข้อมูลจำนวนมาก” อยู่แล้วจากระบบงานหลัก\n",
        "\n",
        "- **ERP (Enterprise Resource Planning)** เก็บข้อมูลกระบวนการธุรกิจ เช่น บัญชี การเงิน จัดซื้อ คลังสินค้า การผลิต\n",
        "- เป้าหมายหลัก: ทำให้ข้อมูล “ถูกต้อง” และ “เป็นมาตรฐานเดียว” เพื่อการควบคุมภายในและการตัดสินใจ\n",
        "\n",
        "ข้อจำกัด:\n",
        "- ออกแบบเพื่อ “งานปฏิบัติการ” (OLTP) มากกว่างานวิเคราะห์เชิงลึก\n",
        "- รายงานหนัก ๆ ทำให้ระบบช้าหรือกระทบงานธุรกรรม\n",
        "\n",
        "---\n",
        "\n",
        "![ERP Visual](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/erp_flow_diagram.png?raw=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2d43b82",
      "metadata": {
        "id": "f2d43b82"
      },
      "source": [
        "### ERP → SAP และการทำมาตรฐานข้อมูลองค์กร\n",
        "\n",
        "- การเติบโตของแพลตฟอร์ม ERP ระดับองค์กร เช่น **SAP** ทำให้ข้อมูลธุรกิจถูกทำให้เป็นมาตรฐาน\n",
        "- องค์กรเริ่มมีข้อมูลที่เชื่อมโยงข้ามหน่วยงานได้มากขึ้น (end-to-end process)\n",
        "\n",
        "ข้อจำกัดที่เริ่มชัด:\n",
        "- ต้องการรายงานและการวิเคราะห์ที่หลากหลายมากขึ้น\n",
        "- งานวิเคราะห์บน OLTP ทำให้เกิดปัญหาคอขวดด้านประสิทธิภาพ\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ead38516",
      "metadata": {
        "id": "ead38516"
      },
      "source": [
        "### OLTP vs OLAP (แยกชนิดงาน)\n",
        "\n",
        "- **OLTP (Online Transaction Processing)**: งานธุรกรรม เน้นเร็วและถูกต้อง (insert/update สูง) เช่น ระบบธนาคาร\n",
        "- **OLAP (Online Analytical Processing)**: งานวิเคราะห์ เน้นการสรุป/รวม/เจาะลึก (scan/aggregate สูง) เช่น ออกรายงานประจำปี\n",
        "\n",
        "บทเรียนสำคัญ:\n",
        "- ระบบเดียวทำทั้ง OLTP และ OLAP พร้อมกันมักทำให้ประสิทธิภาพตกและบริหารยาก\n",
        "\n",
        "---\n",
        "\n",
        "![OLTP Visual](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/oltp_vs_olap_visual.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe181fa4",
      "metadata": {
        "id": "fe181fa4"
      },
      "source": [
        "### Data Warehouse และ ETL (1995–2005)\n",
        "\n",
        "- แนวคิดสำคัญ: แยกพื้นที่วิเคราะห์ออกจากระบบธุรกรรม\n",
        "- ใช้ **ETL** ดึงข้อมูลจากหลายระบบ → ทำความสะอาด/มาตรฐาน → โหลดเข้า Warehouse\n",
        "- รองรับ BI และรายงานย้อนหลัง\n",
        "\n",
        "ข้อจำกัด:\n",
        "- ยืดหยุ่นต่ำ เปลี่ยน schema ยาก\n",
        "- ไม่เหมาะกับข้อมูลนอกตาราง (ข้อความ/ภาพ/ล็อก)\n",
        "- ความหน่วงในการได้ข้อมูล (latency) สูง\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4777d40",
      "metadata": {
        "id": "e4777d40"
      },
      "source": [
        "### การระเบิดของข้อมูลยุคเว็บ (Web-scale)\n",
        "\n",
        "- Web/App ทำให้เกิดข้อมูลชนิดใหม่จำนวนมหาศาล เช่น clickstream, search log, ad impression\n",
        "- ข้อมูลเกิดเร็วและมากกว่าที่ warehouse แบบเดิมรองรับได้\n",
        "\n",
        "ผลที่ตามมา:\n",
        "- ต้องการระบบที่เก็บได้ “มหาศาล” และประมวลผลได้ “แบบกระจาย”\n",
        "\n",
        "\n",
        "\n",
        "**เกร็ดประวัติศาสตร์: Information Explosion (2000s)**\n",
        "การเกิดขึ้นของ Search Engine (Google, Yahoo) และ Social Media (Facebook, Twitter) ทำให้โลกเปลี่ยนจากยุค \"มนุษย์ป้อนข้อมูล\" (Data Entry) เป็นยุค \"มนุษย์ทิ้งร่องรอยดิจิทัล\" (Digital Footprint)\n",
        "- **Crawl & Index**: การเก็บข้อมูลเว็บทั่วโลกต้องใช้วิธีคิดใหม่ที่ไม่ใช่แค่ database\n",
        "- **User Generated Content**: ข้อมูลไม่ได้มาจากองค์กรฝ่ายเดียวอีกต่อไป\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c616f5ee",
      "metadata": {
        "id": "c616f5ee"
      },
      "source": [
        "### แนวคิด Distributed Systems (พื้นฐานสำคัญ)\n",
        "\n",
        "- แบ่งข้อมูลและงานออกเป็นหลายเครื่อง (horizontal scaling)\n",
        "- ได้ throughput สูงขึ้น\n",
        "- ต้องออกแบบให้รองรับความล้มเหลวของเครื่อง (fault tolerance)\n",
        "\n",
        "\n",
        "\n",
        "**เกร็ดความรู้: Site Reliability Engineering (SRE)**\n",
        "ในระบบขนาดใหญ่ที่มีเครื่องเซิร์ฟเวอร์พันเครื่อง \"ความล้มเหลวคือเรื่องปกติ\" (Failure is normal).\n",
        "แนวคิดของ Google SRE คือ:\n",
        "- **\"Hope is not a strategy\"**: อย่าหวังว่า hardware จะไม่พัง\n",
        "- ออกแบบ Software ให้ **resilient**: ถ้าเครื่องพัง 10% ระบบต้องทำงานต่อได้โดย user ไม่รู้ตัว (Redundancy & Failover)\n",
        "\n",
        "---\n",
        "\n",
        "![Site Reliability Engineering Visual](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/sre_concept_visual_1768551934440.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb9f2bed",
      "metadata": {
        "id": "fb9f2bed"
      },
      "source": [
        "### Google File System (GFS) — การเก็บข้อมูลแบบกระจาย\n",
        "\n",
        "- แนวคิด file system แบบกระจายเพื่อเก็บข้อมูลปริมาณมากบนเครื่องราคาทั่วไป\n",
        "- ออกแบบให้ “ล้มได้” แต่ระบบยังทำงานต่อได้\n",
        "\n",
        "\n",
        "\n",
        "**เกร็ดความรู้: หลักการทำงานเบื้องหลัง**\n",
        "- **Chunk Servers**: เครื่องคอมพิวเตอร์ธรรมดา (commodity hardware) จำนวนมากที่เก็บชิ้นส่วนไฟล์\n",
        "- **Master Node**: เครื่องหลักที่คอยจดจำว่า \"ชิ้นส่วนไหน\" เก็บอยู่ที่ \"เครื่องใด\"\n",
        "หากเครื่องใดพัง ระบบจะสำเนาข้อมูลจากเครื่องอื่นมาทดแทนทันที ทำให้ข้อมูลไม่หาย\n",
        "\n",
        "\n",
        "\n",
        "**เกร็ดความรู้: เบื้องหลังความเสถียร (SRE Mindset)**\n",
        "Google มองว่า \"Hardware พังเป็นเรื่องปกติ\" (Failure is normal)\n",
        "- แทนที่จะซื้อ Server ราคาแพงที่ไม่พังง่าย (Supercomputer)\n",
        "- Google ใช้ Commodity Hardware (ราคาถูก) จำนวนมาก แล้วจัดการความเสถียรด้วย Software\n",
        "- **Colossus**: คือระบบไฟล์รุ่นลูกของ GFS ที่พัฒนาขึ้นมาเพื่อแก้ข้อจำกัดเรื่อง Real-time และรองรับไฟล์จำนวนมหาศาลได้ดียิ่งขึ้น (เช่น ใช้ใน YouTube, Drive)\n",
        "\n",
        "---\n",
        "\n",
        "![Google File System Visual](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/gfs_architecture_1768551770079.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a5296d",
      "metadata": {
        "id": "90a5296d"
      },
      "source": [
        "### MapReduce — การประมวลผลแบบแบ่งงาน\n",
        "\n",
        "- Map: กระจายงานย่อยไปหลายเครื่อง\n",
        "- Reduce: รวมผลลัพธ์กลับมาเป็นคำตอบ\n",
        "\n",
        "ข้อดี:\n",
        "- ประมวลผลข้อมูลใหญ่ได้ด้วย cluster\n",
        "\n",
        "ข้อจำกัด:\n",
        "- งานหลายขั้นตอนซับซ้อน\n",
        "- ช้าเพราะต้องอ่าน/เขียนลง disk บ่อย\n",
        "\n",
        "\n",
        "![mapreduce_concept](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/mapreduce_concept_1768464638482.png?raw=1)\n",
        "\n",
        "\n",
        "\n",
        "**ขั้นตอนการทำงาน (Walk-through)**\n",
        "1. **Input**: ข้อมูลขนาดใหญ่ถูกแบ่งเป็นส่วนย่อย\n",
        "2. **Map**: กระจายงานไปให้ Worker หลายเครื่องประมวลผลขนานกัน (เช่น นับคำในแต่ละส่วน)\n",
        "3. **Shuffle**: จัดกลุ่มผลลัพธ์ที่เหมือนกันมารวมกัน (เช่น รวมคำว่า \"Apple\" จากทุกเครื่อง)\n",
        "4. **Reduce**: ผสานผลลัพธ์สุดท้าย (เช่น รวมจำนวน \"Apple\" ทั้งหมดได้ 500 คำ)\n",
        "5. **Output**: เขียนผลลัพธ์ลง Disk\n",
        "\n",
        "\n",
        "\n",
        "**รู้จักกับ Bigtable: ปู่ของ NoSQL**\n",
        "- Google สร้าง **Bigtable** (2006) เพื่อเก็บข้อมูลที่มีโครงสร้างยืดหยุ่น เช่น ข้อมูลหน้าเว็บมหาศาลสำหรับ Google Search\n",
        "- มันเป็นต้นแบบของฐานข้อมูล NoSQL แบบ Wide-column store (เช่น Apache HBase, Cassandra)\n",
        "- จุดเด่นคือการอ่าน/เขียนได้เร็วมาก และขยายตัวได้ง่าย\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da6d65dc",
      "metadata": {
        "id": "da6d65dc"
      },
      "source": [
        "### Bigtable — แนวคิดฐานข้อมูลแบบกระจายระดับเว็บ\n",
        "\n",
        "- รองรับข้อมูลขนาดใหญ่แบบ web-scale\n",
        "- เน้นการ scale ในแนวนอนและ throughput\n",
        "- สะท้อนแนวคิดว่า “ฐานข้อมูลสำหรับยุคเว็บ” ต้องต่างจาก RDBMS แบบเดิม\n",
        "\n",
        "\n",
        "\n",
        "**Bigtable vs RDBMS**\n",
        "- Bigtable ไม่รองรับ SQL เต็มรูปแบบ (ในยุคแรก) และไม่มี Join ที่ซับซ้อน\n",
        "- ออกแบบมาให้ \"Denormalize\" ข้อมูล (เก็บซ้ำได้) เพื่อให้อ่านประมวลผลได้เร็วที่สุด\n",
        "\n",
        "\n",
        "\n",
        "**Bigtable (The Base of Modern NoSQL)**\n",
        "เป็นต้นแบบของ HBase และ Cassandra\n",
        "- **Wide-column store**: เก็บข้อมูลเหมือนตารางยักษ์ที่มีเป็นล้าน column ได้\n",
        "- **Sparse data**: ช่องไหนไม่มีค่า ก็ไม่กินที่เก็บจริง (ต่างจาก RDBMS ที่ NULL ก็อาจกินที่)\n",
        "เหมาะสำหรับเก็บ Web Index หรือ User History ขนาดใหญ่\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3553d87",
      "metadata": {
        "id": "e3553d87"
      },
      "source": [
        "### Colossus — พัฒนาการของระบบจัดเก็บเมื่อข้อมูลโตขึ้น\n",
        "\n",
        "- เมื่อปริมาณและชนิดงานโตขึ้น ระบบจัดเก็บต้องพัฒนาให้จัดการ metadata และการใช้งานหลากหลายได้ดีขึ้น\n",
        "- สะท้อนบทเรียนว่า เมื่อข้อมูลโตเป็นหลายลำดับขนาด (order of magnitude) สถาปัตยกรรม storage ต้องเปลี่ยนตาม\n",
        "\n",
        "\n",
        "\n",
        "**ทำไมต้อง Colossus?**\n",
        "- GFS ยุคแรกมีปัญหาคอขวดที่ Master Node เมื่อไฟล์เยอะเกินไป (Metadata เยอะ)\n",
        "- Colossus กระจายการจัดการ Metadata ทำให้รองรับไฟล์ระดับ Exabyte ได้จริง และรองรับ Real-time Application\n",
        "\n",
        "\n",
        "\n",
        "**Colossus (Next-Gen GFS)**\n",
        "เมื่อ GFS ถูกใช้งานหนักจนถึงขีดจำกัด Google จึงสร้าง Colossus ที่:\n",
        "- จัดการ Metadata ได้เก่งขึ้น (Scale ได้ระดับ Exabyte)\n",
        "- รองรับ Real-time ได้ดีขึ้น (เพราะบริการเริ่มต้องการความไว)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3720380c",
      "metadata": {
        "id": "3720380c"
      },
      "source": [
        "### Hadoop Ecosystem (2005–2012)\n",
        "\n",
        "- HDFS: แนวคิด storage แบบกระจาย\n",
        "- MapReduce: batch processing บน cluster\n",
        "\n",
        "บทบาททางประวัติศาสตร์:\n",
        "- ทำให้แนวคิด Big Data เข้าถึงได้ในวงกว้างผ่าน open-source\n",
        "\n",
        "ข้อจำกัด:\n",
        "- Disk-based → latency สูง\n",
        "- พัฒนาและดูแลซับซ้อน\n",
        "\n",
        "---\n",
        "\n",
        "![Hadoop Visual](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/hadoop_landscape_diagram_1768551956356.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04f42bd2",
      "metadata": {
        "id": "04f42bd2"
      },
      "source": [
        "### NoSQL — เมื่อ RDBMS ไม่ตอบโจทย์ข้อมูลยุคใหม่\n",
        "\n",
        "- Key-value / Document / Columnar\n",
        "- จุดแข็ง: scale ง่าย รองรับข้อมูลหลากหลายรูปแบบ และ schema ยืดหยุ่น\n",
        "- จุดอ่อน: คุณสมบัติด้านความสอดคล้องของข้อมูล (consistency) และการ query บางรูปแบบอาจต่างจาก RDBMS (ขึ้นกับระบบ)\n",
        "\n",
        "**บทเรียนเชิงสถาปัตยกรรม**\n",
        "- บางครั้งระบบต้อง “ยอมแลก” บางคุณสมบัติเพื่อแลกกับการ scale และความยืดหยุ่น\n",
        "\n",
        "\n",
        "\n",
        "**เกร็ดความรู้: CAP Theorem**\n",
        "ในระบบกระจาย เรามักต้องเลือกระหว่าง:\n",
        "- **Consistency (C)**: ข้อมูลตรงกันทุกเครื่องทันที\n",
        "- **Availability (A)**: ระบบตอบสนองเสมอแม้บางส่วนมีปัญหา\n",
        "NoSQL ส่วนใหญ่มักเลือก A (ตอบสนองไว) และยอมลด C (ข้อมูลอาจจะ update ไม่พร้อมกันเสี้ยววินาที - Eventual Consistency)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "![NoSQL Visual](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/nosql_types_quadrant_1768551979683.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a562289d",
      "metadata": {
        "id": "a562289d"
      },
      "source": [
        "### Apache Spark (2012+)\n",
        "\n",
        "- In-memory processing ช่วยลดเวลาประมวลผลอย่างมีนัยสำคัญ (เร็วกว่า Hadoop MapReduce ถึง 100 เท่าในบาง tasks)\n",
        "- API ระดับสูง (DataFrame, SQL) ทำให้พัฒนาได้เร็วและปลอดภัยขึ้น\n",
        "- รองรับงานหลายแบบ: Batch, Streaming, Machine Learning, Graph Processing\n",
        "\n",
        "\n",
        "![spark_in_memory_vs_disk](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/spark_in_memory_vs_disk_1768465074016.png?raw=1)\n",
        "\n",
        "---\n",
        "\n",
        "![Hadoop Visual](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/hadoop_ecosystem_landscape_1768466526224.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "828f4be5",
      "metadata": {
        "id": "828f4be5"
      },
      "source": [
        "### Cloud และแนวคิดแยก Storage กับ Compute\n",
        "\n",
        "- Elasticity: เพิ่ม/ลดทรัพยากรได้ตามต้องการ\n",
        "- Pay-as-you-go: จ่ายตามการใช้งานจริง\n",
        "- แยกที่เก็บข้อมูล (object storage) ออกจากเครื่องประมวลผล (compute)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c809b64",
      "metadata": {
        "id": "4c809b64"
      },
      "source": [
        "### Data Lake — เก็บข้อมูลดิบเพื่อความยืดหยุ่น\n",
        "\n",
        "- เก็บข้อมูลดิบจำนวนมาก รองรับหลายรูปแบบ\n",
        "- schema-on-read ทำให้ยืดหยุ่นต่อคำถามใหม่ ๆ\n",
        "\n",
        "ข้อควรระวัง:\n",
        "- หากไม่มี governance จะกลายเป็น data swamp\n",
        "\n",
        "\n",
        "![datalake_vs_warehouse](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/datalake_vs_warehouse_1768464684861.png?raw=1)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a15d09",
      "metadata": {
        "id": "53a15d09"
      },
      "source": [
        "### Lakehouse และสรุปวิวัฒนาการ\n",
        "\n",
        "- Lakehouse รวมข้อดีของ Data Lake + Warehouse (เช่นความถูกต้องแบบ ACID บนไฟล์)\n",
        "- แนวโน้มปัจจุบัน: analytics + ML + streaming บนข้อมูลชุดเดียวที่บริหารจัดการได้ดี\n",
        "\n",
        "**ช่วงถาม–คิด (ปิดท้าย)**\n",
        "- หากคุณเป็นองค์กรขนาดกลาง คุณควรเริ่มจากแนวคิดใดยุคใดก่อน และเพราะเหตุใด\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc9650ff",
      "metadata": {
        "id": "cc9650ff"
      },
      "source": [
        "## Part 4: ทำไม Python ถึงเป็นภาษาหลักของ Big Data\n",
        "\n",
        "### เหตุผลสำคัญ\n",
        "- **อ่านง่าย (Readability)**: โครงสร้างภาษาที่ใกล้เคียงภาษาอังกฤษ ทำให้เรียนรู้ได้เร็ว\n",
        "- **Abstraction สูง**: ซ่อนความซับซ้อนของ memory management ทำให้โฟกัสที่ logic ได้\n",
        "- **Performance ดี**: เมื่อใช้ร่วมกับไลบรารีอย่าง NumPy หรือ Pandas ที่เขียนด้วย C/C++\n",
        "- **Ecosystem**: มีเครื่องมือครบวงจรสำหรับ Data Science (Pandas, Scikit-learn, TensorFlow)\n",
        "- **Portability**: ใช้งานได้ข้ามแพลตฟอร์ม (Windows, Mac, Linux, Cloud)\n",
        "\n",
        "**ตัวอย่างการนำไปใช้**\n",
        "- เริ่มวิเคราะห์ด้วย Pandas/NumPy ใน notebook → ย้าย logic เดียวกันไปใช้ Spark DataFrame/SQL ได้แทบไม่ต้องเปลี่ยนภาษา\n",
        "- ระบบ orchestration (Airflow/Prefect) และ workflow ML/Analytics ส่วนใหญ่รองรับ Python โดยตรง จึงเขียน pipeline ต่อเนื่องตั้งแต่ ingest → transform → model → dashboard ได้ในภาษาเดียว\n",
        "- ชุมชนโอเพ่นซอร์สอัปเดตเร็ว เมื่อมีเครื่องมือใหม่ในสายข้อมูล (เช่น DuckDB, Polars, PySpark API ใหม่) มักมี binding ภาษา Python ให้ลองได้เร็วที่สุด\n",
        "\n",
        "![python_data_ecosystem](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/python_data_ecosystem_1768465097331.png?raw=1)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1a7aec",
      "metadata": {
        "id": "3e1a7aec"
      },
      "source": [
        "## Part 5: Python พื้นฐาน (Hands-on)\n",
        "\n",
        "> **เหตุผลที่ต้องเรียนพื้นฐานให้เป็นระบบก่อน**\n",
        "> งาน Big Data ในทางปฏิบัติไม่ได้เริ่มจากการกดปุ่มในเครื่องมือ แต่เริ่มจากการเขียน “กระบวนการ” ที่ทำซ้ำได้ เช่น การอ่านข้อมูล การทำความสะอาด การแปลงรูปแบบ และการวิเคราะห์\n",
        "\n",
        "### ทำไมต้องมีพัฒนาการของแนวคิด (Concept Evolution) ใน Python\n",
        "แนวคิดในภาษาโปรแกรมพัฒนามาจากความต้องการทำให้โค้ด:\n",
        "1) **อ่านง่าย** (readability)\n",
        "2) **ดูแลง่าย** (maintainability)\n",
        "3) **ขยายได้** (scalability of code)\n",
        "4) **ทำงานร่วมกันได้** (collaboration)\n",
        "\n",
        "กล่าวโดยสรุป: เมื่อระบบโตขึ้น การเขียนโค้ดแบบ “คิดเป็นส่วน” (abstraction) และ “มีโครงสร้าง” จะสำคัญมากกว่าการจำคำสั่ง\n",
        "\n",
        "### เชื่อมกับ Data Science Libraries\n",
        "ในโลกข้อมูล Python ถูกใช้อย่างกว้างขวางเพราะมีไลบรารีที่แปลงงานยากให้เป็นคำสั่งระดับสูง เช่น\n",
        "- **NumPy**: คำนวณเชิงตัวเลขและอาร์เรย์อย่างมีประสิทธิภาพ\n",
        "- **Pandas**: จัดการข้อมูลเชิงตาราง (เหมือน spreadsheet แต่ทรงพลังและทำซ้ำได้)\n",
        "- **Matplotlib**: สร้างกราฟเพื่อสื่อสารผลลัพธ์\n",
        "\n",
        "> หลังจากพื้นฐานส่วนนี้ นักศึกษาจะพร้อมเข้าสู่การจัดการข้อมูลด้วย Pandas และขยายไปสู่เครื่องมือ Big Data ในสัปดาห์ถัดไป\n",
        "\n",
        "### แนวทางการฝึกให้ได้ผล\n",
        "- Run ทีละ cell แล้วลองแก้ค่าตัวแปร/เงื่อนไขดูผลลัพธ์ทันทีเพื่อเห็น feedback\n",
        "- จดสิ่งที่เปลี่ยนแปลงเมื่อเพิ่มวงเล็บ/เรียงลำดับคำสั่ง (ช่วยเรื่อง debugging และการอ่านโค้ดคนอื่น)\n",
        "- เก็บ snippet ที่ใช้บ่อยไว้ในไฟล์ย่อยหรือ gist เพื่อ reuse ตอนทำ project/assignment\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "146f7f00",
      "metadata": {
        "id": "146f7f00"
      },
      "source": [
        "### 5.1 Variable & Operation\n",
        "\n",
        "**แนวคิด**\n",
        "ตัวแปรคือชื่อที่ใช้อ้างอิงข้อมูลในหน่วยความจำ เพื่อใช้งานซ้ำได้อย่างเป็นระบบ ส่วน operation คือการคำนวณ/แปลงข้อมูล ซึ่งเป็นหัวใจของการสร้างตัวแปรใหม่และตัวชี้วัดในงานข้อมูลจริง\n",
        "\n",
        "**เปรียบเทียบให้เห็นภาพ**\n",
        "ตัวแปรเหมือน \"กล่องแปะป้ายชื่อ\"\n",
        "- เราสร้างกล่องชื่อ `score` แล้วใส่ค่า `10` ลงไป\n",
        "- เมื่อเราสั่ง `score = 20` คือการเทค่าเดิมทิ้งแล้วใส่ `20` ลงไปแทน\n",
        "- หรือมองว่าป้ายชื่อ `score` ย้ายไปแปะที่ข้อมูลตัวใหม่ก็ได้ (ใน Python จะเป็นแบบนี้)\n",
        "\n",
        "**เคล็ดลับเชิงปฏิบัติ**\n",
        "- Python เป็น dynamically typed: ชื่อตัวแปรชี้ไปที่ object เดิม หากต้องการ copy list/dict ให้ใช้ `.copy()` หรือ slicing (`nums[:]`) ไม่เช่นนั้นการแก้ไขจะกระทบตัวแปรที่อ้างอิงร่วมกัน\n",
        "- ตรวจสอบชนิดและแปลงประเภทด้วย `type(x)`, `int()`, `float()`, `str()` เพื่อให้คำนวณได้ถูกต้องหลังอ่านไฟล์\n",
        "- ตั้งชื่อตัวแปรแบบ `snake_case` ที่สื่อความหมายต่อการวิเคราะห์ เช่น `total_sales`, `avg_latency_ms`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f27f2ab",
      "metadata": {
        "id": "6f27f2ab"
      },
      "outputs": [],
      "source": [
        "# ตัวอย่าง 1: การกำหนดตัวแปรและคำนวณพื้นฐาน\n",
        "a = 10\n",
        "b = 3\n",
        "\n",
        "(a + b, a - b, a * b, a / b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a791c2f3",
      "metadata": {
        "id": "a791c2f3"
      },
      "outputs": [],
      "source": [
        "# ตัวอย่าง 2: Arithmetic operations (ครบชุด)\n",
        "# +  บวก\n",
        "# -  ลบ\n",
        "# *  คูณ\n",
        "# /  หาร (float)\n",
        "# // หารปัดเศษลง\n",
        "# %  หารเอาเศษ\n",
        "# ** ยกกำลัง\n",
        "\n",
        "a = 17\n",
        "b = 5\n",
        "{\n",
        "    \"a + b\": a + b,\n",
        "    \"a - b\": a - b,\n",
        "    \"a * b\": a * b,\n",
        "    \"a / b\": a / b,\n",
        "    \"a // b\": a // b,\n",
        "    \"a % b\": a % b,\n",
        "    \"a ** b\": a ** b,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1983d651",
      "metadata": {
        "id": "1983d651"
      },
      "outputs": [],
      "source": [
        "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60523887",
      "metadata": {
        "id": "60523887"
      },
      "outputs": [],
      "source": [
        "# ตัวอย่าง 3: Augmented assignment\n",
        "x = 10\n",
        "x += 3   # x = x + 3\n",
        "x -= 1   # x = x - 1\n",
        "x *= 2   # x = x * 2\n",
        "x /= 4   # x = x / 4\n",
        "x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a3d1340",
      "metadata": {
        "id": "4a3d1340"
      },
      "outputs": [],
      "source": [
        "# ตัวอย่าง 4: Comparison operations\n",
        "a = 10\n",
        "b = 3\n",
        "{\n",
        "    \"a == b\": a == b,\n",
        "    \"a != b\": a != b,\n",
        "    \"a > b\": a > b,\n",
        "    \"a >= b\": a >= b,\n",
        "    \"a < b\": a < b,\n",
        "    \"a <= b\": a <= b,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc2c7805",
      "metadata": {
        "id": "dc2c7805"
      },
      "outputs": [],
      "source": [
        "# ตัวอย่าง 5: Logical operations\n",
        "age = 19\n",
        "is_student = True\n",
        "\n",
        "eligible = (age >= 18) and is_student\n",
        "eligible, (not eligible), (eligible or False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05b4f66e",
      "metadata": {
        "id": "05b4f66e"
      },
      "source": [
        "### 5.2 Data Types\n",
        "\n",
        "**แนวคิด**\n",
        "ชนิดข้อมูลมีผลต่อการคำนวณและความหมายของข้อมูล เช่น การบวกเลขกับการต่อข้อความเป็นคนละความหมายกัน\n",
        "\n",
        "**ชนิดข้อมูลพื้นฐานที่ใช้บ่อย**\n",
        "- `int`, `float`: ตัวเลขสำหรับคำนวณทางคณิตศาสตร์และสถิติ\n",
        "- `bool`: ค่า True/False; ค่า 0, `\"\"`, `[]`, `{}` จะถูกมองเป็น False (truthiness) จึงใช้ตรวจค่าว่างได้เร็ว\n",
        "- `str`: ข้อความ ใช้บ่อยเมื่อ ingest ข้อมูลจากไฟล์/ API ก่อนแปลงเป็นตัวเลข\n",
        "- `list`, `tuple`, `set`, `dict`: โครงสร้างเก็บหลายค่า เป็นรากฐานของการจัดกลุ่มข้อมูลก่อนวิเคราะห์\n",
        "- `None`: แทนค่าที่ไม่มี/ยังไม่กำหนด ใช้ตรวจสอบก่อนคำนวณเพื่อเลี่ยง error\n",
        "\n",
        "ใช้ `type(x)` หรือ `isinstance(x, (int, float))` เพื่อตรวจสอบชนิด และใช้ฟังก์ชันแปลง (`int(\"10\")`, `float(\"3.14\")`) เมื่อ ingest ข้อมูลที่เป็นข้อความ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49f05ec3",
      "metadata": {
        "id": "49f05ec3"
      },
      "outputs": [],
      "source": [
        "x = 10          # int\n",
        "y = 3.14        # float\n",
        "name = \"Data\"   # string\n",
        "flag = True     # boolean\n",
        "\n",
        "(type(x), type(y), type(name), type(flag))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "386998eb",
      "metadata": {
        "id": "386998eb"
      },
      "outputs": [],
      "source": [
        "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0d55c4b",
      "metadata": {
        "id": "e0d55c4b"
      },
      "source": [
        "**ช่วงถาม–คิด**\n",
        "- หากอ่านข้อมูลจากไฟล์แล้วตัวเลขถูกตีความเป็น string จะกระทบการวิเคราะห์อย่างไร\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b35aef1",
      "metadata": {
        "id": "5b35aef1"
      },
      "source": [
        "### 5.3 Python Reserved Words (Keywords)\n",
        "\n",
        "**แนวคิด**\n",
        "คำสงวน (reserved words หรือ keywords) คือคำที่ Python จองไว้ใช้เป็นไวยากรณ์ของภาษา จึงไม่ควรนำไปตั้งเป็นชื่อตัวแปรหรือชื่อฟังก์ชัน\n",
        "\n",
        "**ทิปสำหรับการเขียนโค้ดจริง**\n",
        "- ดูรายการคำต้องห้ามได้ด้วย `import keyword; keyword.kwlist`\n",
        "- หลีกเลี่ยงการตั้งชื่อทับ builtins ที่ไม่ใช่ keyword เช่น `list`, `dict`, `id` เพราะจะทำให้เรียกฟังก์ชันมาตรฐานไม่ได้หรืออ่านยากขึ้น (ใช้ `student_list` แทน `list`)\n",
        "- หากจำเป็นต้องใช้ชื่อเดียวกับ keyword ในการสื่อความหมาย ให้เติม `_` ต่อท้าย เช่น `class_` เพื่อเลี่ยงการชนกับ syntax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce1b9fdc",
      "metadata": {
        "id": "ce1b9fdc"
      },
      "outputs": [],
      "source": [
        "import keyword\n",
        "keyword.kwlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ddbc75c",
      "metadata": {
        "id": "1ddbc75c"
      },
      "outputs": [],
      "source": [
        "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5662699d",
      "metadata": {
        "id": "5662699d"
      },
      "source": [
        "**ตัวอย่างข้อควรระวัง**\n",
        "- ไม่ควรตั้งชื่อตัวแปรเป็น `class`, `def`, `for`, `if`, `import`, `return` เป็นต้น\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b1e47c",
      "metadata": {
        "id": "d1b1e47c"
      },
      "source": [
        "### 5.4 Data Structures\n",
        "\n",
        "**แนวคิด**\n",
        "โครงสร้างข้อมูลช่วยให้จัดเก็บและจัดการข้อมูลหลายค่าพร้อมกันได้อย่างเป็นระบบ ซึ่งเป็นพื้นฐานของการเตรียมข้อมูลก่อนวิเคราะห์\n",
        "\n",
        "**เลือกใช้ให้เหมาะกับงาน**\n",
        "- `list`: เก็บข้อมูลเรียงลำดับ มีค่าซ้ำได้ เหมาะกับลำดับเหตุการณ์หรือ batch processing เล็ก ๆ\n",
        "- `tuple`: ข้อมูลที่ไม่ควรเปลี่ยน เช่น พิกัด (lat, long) หรือ config ที่ต้องตรึงค่า\n",
        "- `set`: เก็บค่าไม่ซ้ำ เช็กสมาชิกได้เร็ว เหมาะกับการ deduplicate หรือหาจุดตัดของกลุ่มข้อมูล\n",
        "- `dict`: mapping key → value ใช้ดึงข้อมูลตามรหัส/ชื่อเฉพาะ หรือเก็บข้อมูลรูปแบบ JSON\n",
        "- โครงสร้างเหล่านี้สามารถผสมกับ loop หรือ comprehension เพื่อแปลงข้อมูลเป็นขั้นตอน ๆ ได้"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdeea767",
      "metadata": {
        "id": "cdeea767"
      },
      "source": [
        "#### List\n",
        "\n",
        "**การใช้งานจริง**\n",
        "- เหมาะกับข้อมูลที่มีลำดับและอาจมีค่าซ้ำ เช่น log events, รายการซื้อสินค้า\n",
        "- คำสั่งพื้นฐานที่ใช้บ่อย: `append`, `pop`, `extend`, slicing (`numbers[1:3]`) และการหาความยาวด้วย `len(numbers)`\n",
        "- List comprehension ช่วยกรอง/แปลงข้อมูลในบรรทัดเดียว เช่น `[x**2 for x in numbers if x % 2 == 0]`\n",
        "\n",
        "**List vs Tuple (เกร็ดเพิ่มเติม)**\n",
        "- **List `[]`**: เหมือน \"กระดาษทด\" ที่เราเขียนเพิ่ม ลบ แก้ไข ได้ตลอดเวลา (Mutable)\n",
        "- **Tuple `()`**: เหมือน \"แผ่นศิลาจารึก\" ที่เขียนแล้วเปลี่ยนไม่ได้ (Immutable) เหมาะกับข้อมูลที่ต้องคงที่ เช่น พิกัด (lat, long) หรือค่า config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66b2e5d7",
      "metadata": {
        "id": "66b2e5d7"
      },
      "outputs": [],
      "source": [
        "numbers = [1, 2, 3, 4]\n",
        "\n",
        "numbers.append(5)                  # เพิ่มค่าที่ท้ายลิสต์\n",
        "first_two = numbers[:2]            # ตัด slice เพื่อหยิบบางส่วน\n",
        "numbers.remove(3)                  # ลบค่าแรกที่พบ\n",
        "squared_even = [n**2 for n in numbers if n % 2 == 0]\n",
        "\n",
        "{\n",
        "    \"numbers\": numbers,\n",
        "    \"first_two\": first_two,\n",
        "    \"squared_even\": squared_even,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc3c79bd",
      "metadata": {
        "id": "cc3c79bd"
      },
      "source": [
        "#### Tuple\n",
        "\n",
        "ใช้เก็บข้อมูลที่ไม่ควรแก้ไข เช่น พิกัด (lat, long), สี (r, g, b) หรือ config ที่ต้องตรึงค่า และยังถูกใช้เป็น key ของ dict ได้เพราะเป็น immutable\n",
        "\n",
        "- เหมาะกับการ \"จับคู่\" ข้อมูลที่ต้องใช้ร่วมกันเสมอ เช่น `(ชื่อ, คะแนน)` หรือ `(ปี, ไตรมาส)`\n",
        "- Tuple unpacking (`lat, lon = coords`) ช่วยให้อ่านค่าหลายตัวได้ในบรรทัดเดียว"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff750035",
      "metadata": {
        "id": "ff750035"
      },
      "outputs": [],
      "source": [
        "coords = (13.75, 100.50)\n",
        "lat, lon = coords  # tuple unpacking\n",
        "\n",
        "student_info = (\"Alice\", 85)\n",
        "name, score = student_info\n",
        "\n",
        "{\n",
        "    \"coords\": coords,\n",
        "    \"lat_lon\": (lat, lon),\n",
        "    \"student\": {\"name\": name, \"score\": score},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58b7d940",
      "metadata": {
        "id": "58b7d940"
      },
      "source": [
        "#### Set\n",
        "\n",
        "Set คือกลุ่มข้อมูลที่ไม่มีลำดับและไม่เก็บค่าซ้ำ ใช้เช็กสมาชิกหรือทำ operation ทางเซตได้รวดเร็ว เหมาะกับงาน deduplicate, whitelist/blacklist, หรือหาจุดตัดของกลุ่มข้อมูล\n",
        "\n",
        "- `in` สำหรับตรวจสอบสมาชิกทำงานเร็วมาก (O(1) โดยประมาณ)\n",
        "- การดำเนินการที่ใช้บ่อย: union (`|`), intersection (`&`), difference (`-`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1832a189",
      "metadata": {
        "id": "1832a189"
      },
      "outputs": [],
      "source": [
        "tags = {\"python\", \"data\", \"etl\", \"python\"}  # ค่าซ้ำถูกตัดออกอัตโนมัติ\n",
        "new_tags = {\"cloud\", \"etl\", \"spark\"}\n",
        "\n",
        "results = {\n",
        "    \"unique_tags\": tags,\n",
        "    \"intersection\": tags & new_tags,\n",
        "    \"union\": tags | new_tags,\n",
        "    \"difference\": tags - new_tags,\n",
        "    \"contains_etl\": \"etl\" in tags,\n",
        "}\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b9e0334",
      "metadata": {
        "id": "3b9e0334"
      },
      "source": [
        "#### Dictionary\n",
        "\n",
        "- จัดเก็บข้อมูลแบบ key → value เหมาะกับการค้นหาเร็ว ๆ ตามรหัสหรือตัวระบุ เช่น `student_id -> คะแนน`\n",
        "- ใช้บ่อยกับข้อมูล JSON ที่ซ้อนกัน (nested dict) สามารถเข้าถึงค่าลึก ๆ ได้ด้วย `dict[\"key\"][\"subkey\"]`\n",
        "- ควรใช้ `.get()` เมื่อ key อาจหายไปเพื่อลดโอกาสเกิด KeyError และสามารถกำหนดค่าดีฟอลต์ได้\n",
        "- key ต้องเป็นชนิดที่ hash ได้ (immutable) เช่น `str`, `int`, `tuple` ส่วน `list` ใช้เป็น key ไม่ได้"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aff0be4e",
      "metadata": {
        "id": "aff0be4e"
      },
      "outputs": [],
      "source": [
        "student = {\"name\": \"Alice\", \"score\": 85, \"courses\": [\"DS101\", \"ML201\"]}\n",
        "\n",
        "student[\"score\"] += 5                 # update ค่า\n",
        "student.setdefault(\"major\", \"Data Science\")  # ใส่ค่า default หากยังไม่มี key\n",
        "\n",
        "{\n",
        "    \"score\": student[\"score\"],\n",
        "    \"first_course\": student[\"courses\"][0],\n",
        "    \"has_gpa\": \"gpa\" in student,\n",
        "    \"summary\": f\"{student['name']} ({student['major']})\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3edc4082",
      "metadata": {
        "id": "3edc4082"
      },
      "outputs": [],
      "source": [
        "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99e24c6e",
      "metadata": {
        "id": "99e24c6e"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e43656a",
      "metadata": {
        "id": "5e43656a"
      },
      "source": [
        "### 5.5 Condition\n",
        "\n",
        "**แนวคิด**\n",
        "โครงสร้างเงื่อนไขใช้กำหนดเส้นทางการทำงานของโปรแกรมตามสถานการณ์ที่แตกต่างกัน เป็นพื้นฐานของตรรกะในงานข้อมูล (เช่น การคัดกรอง/จัดกลุ่ม)\n",
        "\n",
        "**แนวทางใช้ใน pipeline**\n",
        "- ใช้กรองแถวที่ผ่านเกณฑ์ เช่น เฉพาะลูกค้าที่ active หรือคำสั่งซื้อที่ยอดเกิน 1,000\n",
        "- ใช้ guard clause ตรวจสอบ input/config ก่อนทำงานจริง (`if not data: return []`) เพื่อลด error downstream\n",
        "- จำไว้ว่า `0`, ค่า `None`, ค่าว่าง (`[]`, `{}`, `\"\"`) จะ evaluate เป็น False จึงใช้เช็ก missing/empty ได้อย่างรวดเร็ว"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b92f4f33",
      "metadata": {
        "id": "b92f4f33"
      },
      "outputs": [],
      "source": [
        "score = 72\n",
        "\n",
        "if score >= 80:\n",
        "    result = \"A\"\n",
        "elif score >= 70:\n",
        "    result = \"B\"\n",
        "else:\n",
        "    result = \"C\"\n",
        "\n",
        "result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cd9b2b9",
      "metadata": {
        "id": "1cd9b2b9"
      },
      "source": [
        "**ช่วงถาม–คิด**\n",
        "- หากเพิ่มเกณฑ์คะแนนใหม่ ต้องปรับโค้ดส่วนใด\n",
        "- ระบบให้เกรดขนาดใหญ่ควรใช้ if-else อย่างเดียวเพียงพอหรือไม่\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bdb3b87",
      "metadata": {
        "id": "5bdb3b87"
      },
      "source": [
        "### 5.6 Loop\n",
        "\n",
        "**แนวคิด**\n",
        "ลูปช่วยให้ทำงานซ้ำได้อัตโนมัติ เหมาะกับงานที่ต้องทำกับข้อมูลหลายรายการ เช่น การคำนวณค่าจากหลายแถว หรือการประมวลผลรายการข้อมูล\n",
        "\n",
        "![loop_logic_flowchart](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/loop_logic_flowchart_1768465154736.png?raw=1)\n",
        "\n",
        "**เลือกใช้ลูปแบบไหน**\n",
        "- `for` เหมาะกับจำนวนรอบชัดเจน เช่น loop ผ่านรายการข้อมูล; `while` ใช้เมื่อรอเงื่อนไขบางอย่างเกิดขึ้น\n",
        "- ใช้ `enumerate` เมื่อต้องการทั้ง index และค่า หรือ `break`/`continue` เพื่อควบคุมทิศทางการทำงาน\n",
        "- ถ้าเป้าหมายคือสร้าง collection ใหม่จากข้อมูลเดิม ให้พิจารณา list/dict comprehension เพื่อให้โค้ดสั้นและอ่านง่าย"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "662a2e13",
      "metadata": {
        "id": "662a2e13"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f13f5c1a",
      "metadata": {
        "id": "f13f5c1a"
      },
      "outputs": [],
      "source": [
        "numbers = [1, 2, 3]\n",
        "for n in numbers:\n",
        "    print(n * 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4679335",
      "metadata": {
        "id": "a4679335"
      },
      "outputs": [],
      "source": [
        "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27c99750",
      "metadata": {
        "id": "27c99750"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6634e19",
      "metadata": {
        "id": "e6634e19"
      },
      "source": [
        "### 5.6.1 Function\n",
        "\n",
        "**แนวคิด**\n",
        "ฟังก์ชันช่วยย่อยโค้ดเป็นหน่วยย่อย ทำให้โค้ดอ่านง่าย ทดสอบง่าย และนำกลับมาใช้ซ้ำได้ ซึ่งสำคัญมากเมื่อโครงงานมีหลายขั้นตอน\n",
        "\n",
        "**Best Practice**\n",
        "- 1 ฟังก์ชัน ควรทำแค่ 1 หน้าที่\n",
        "- ชื่อฟังก์ชันควรเป็น \"คำกริยา\" ที่สื่อความหมาย เช่น `calculate_tax()`, `clean_data()`\n",
        "- หากฟังก์ชันยาวเกินไป ควรแตกเป็นฟังก์ชันย่อย\n",
        "\n",
        "**เสริมจากประสบการณ์จริง**\n",
        "- ใช้ default arguments เพื่อค่าเริ่มต้นที่สมเหตุสมผล แต่หลีกเลี่ยง default ที่เป็น mutable (`[]`, `{}`)\n",
        "- ใส่ type hints และ docstring สั้น ๆ เพื่อให้ทีมอื่นเข้าใจ input/output ชัดเจน\n",
        "- แยก logic หลักออกจาก I/O (อ่านไฟล์/เขียนไฟล์) เพื่อให้ทดสอบได้ง่ายและลดผลข้างเคียง"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8ca26b",
      "metadata": {
        "id": "3c8ca26b"
      },
      "outputs": [],
      "source": [
        "def average(x, y):\n",
        "    return (x + y) / 2\n",
        "\n",
        "average(10, 20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff6c5e5",
      "metadata": {
        "id": "bff6c5e5"
      },
      "outputs": [],
      "source": [
        "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f2fd183",
      "metadata": {
        "id": "7f2fd183"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32ad14f6",
      "metadata": {
        "id": "32ad14f6"
      },
      "source": [
        "### 5.7 Class & Object\n",
        "\n",
        "**แนวคิด**\n",
        "เมื่อโปรแกรมมีความซับซ้อนมากขึ้น เราต้องจัดกลุ่ม “ข้อมูล” และ “พฤติกรรม” ให้อยู่ด้วยกันอย่างเป็นระบบ (Object-Oriented Programming)\n",
        "\n",
        "- **Class** คือแม่แบบที่กำหนดว่าออบเจ็กต์ควรมีข้อมูล (attributes) และความสามารถ (methods) อะไร\n",
        "- **Object (Instance)** คือสิ่งที่ถูกสร้างจาก class\n",
        "\n",
        "เหตุผลที่ใช้ class/object:\n",
        "- ทำให้โค้ดอ่านง่ายขึ้นเมื่อระบบใหญ่\n",
        "- ลดความซ้ำซ้อน\n",
        "- แยกความรับผิดชอบของแต่ละส่วน (encapsulation)\n",
        "\n",
        "![class_vs_object_metaphor](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/class_vs_object_metaphor_1768465178507.png?raw=1)\n",
        "\n",
        "**เคล็ดลับการออกแบบเบื้องต้น**\n",
        "- กำหนด `__repr__` หรือ `__str__` เพื่อช่วย debug/แสดงผลสรุปข้อมูล\n",
        "- หาก class เน้นเก็บข้อมูลเป็นหลัก พิจารณาใช้ `@dataclass` เพื่อลดโค้ด boilerplate\n",
        "- แยก business rule ให้เป็น method ที่ชัดเจน (เช่น `apply_bonus()`, `is_pass()`) เพื่อ reuse ใน pipeline อื่น"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77bd23ba",
      "metadata": {
        "id": "77bd23ba"
      },
      "outputs": [],
      "source": [
        "# ตัวอย่าง 1: Class พื้นฐาน (Student)\n",
        "class Student:\n",
        "    def __init__(self, name, score):\n",
        "        self.name = name\n",
        "        self.score = score\n",
        "\n",
        "    def grade(self):\n",
        "        return \"Pass\" if self.score >= 60 else \"Fail\"\n",
        "\n",
        "s1 = Student(\"Bob\", 75)\n",
        "s2 = Student(\"Alice\", 55)\n",
        "\n",
        "(s1.name, s1.score, s1.grade()), (s2.name, s2.score, s2.grade())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55b3ecfc",
      "metadata": {
        "id": "55b3ecfc"
      },
      "outputs": [],
      "source": [
        "# ตัวอย่าง 2: เพิ่มพฤติกรรมและการปรับปรุงข้อมูล (Update)\n",
        "class Student:\n",
        "    def __init__(self, name, score):\n",
        "        self.name = name\n",
        "        self.score = score\n",
        "\n",
        "    def add_bonus(self, bonus):\n",
        "        self.score += bonus\n",
        "\n",
        "    def grade(self):\n",
        "        return \"Pass\" if self.score >= 60 else \"Fail\"\n",
        "\n",
        "    def summary(self):\n",
        "        return f\"{self.name}: score={self.score}, status={self.grade()}\"\n",
        "\n",
        "s = Student(\"Chris\", 58)\n",
        "s.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77e8d158",
      "metadata": {
        "id": "77e8d158"
      },
      "outputs": [],
      "source": [
        "s.add_bonus(5)\n",
        "s.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d36e2369",
      "metadata": {
        "id": "d36e2369"
      },
      "outputs": [],
      "source": [
        "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cb0fc09",
      "metadata": {
        "id": "6cb0fc09"
      },
      "source": [
        "**ช่วงถาม–คิด**\n",
        "- หากระบบมีนักศึกษาหลายพันคน class/object ช่วยให้จัดการกฎและการคำนวณได้อย่างไร\n",
        "- แนวคิดนี้เชื่อมกับการออกแบบ pipeline หรือ dataset object ได้อย่างไร\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1b5f08c",
      "metadata": {
        "id": "b1b5f08c"
      },
      "source": [
        "### 5.8 Import Module\n",
        "\n",
        "**แนวคิด**\n",
        "การนำเข้าโมดูลทำให้เราใช้ความสามารถที่มีอยู่แล้วในมาตรฐานของภาษาและไลบรารีภายนอก ลดการเขียนซ้ำและทำให้ทำงานบนมาตรฐานเดียวกัน\n",
        "\n",
        "**แนวทางปฏิบัติ**\n",
        "- ใช้ alias ที่เป็นมาตรฐานเพื่อให้อ่านง่าย เช่น `import numpy as np`, `import pandas as pd`\n",
        "- จัดกลุ่ม import ไว้ตอนต้นไฟล์ โดยแยก standard library, third-party, และโมดูลภายในโปรเจ็กต์เพื่อให้สแกนง่าย\n",
        "- เมื่อใช้ virtual environment ให้บันทึก dependency ด้วย `requirements.txt` หรือ `pip freeze > requirements.txt` เพื่อย้ายสภาพแวดล้อมได้สะดวก\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e82cec4b",
      "metadata": {
        "id": "e82cec4b"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "math.sqrt(16)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "351d6373",
      "metadata": {
        "id": "351d6373"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "299fe364",
      "metadata": {
        "id": "299fe364"
      },
      "source": [
        "## Part 6: Python สำหรับ Data Science\n",
        "\n",
        "### 6.1 NumPy\n",
        "\n",
        "**แนวคิด**\n",
        "NumPy เป็นไลบรารีพื้นฐานด้านการคำนวณเชิงตัวเลข (numerical computing) โดยออกแบบให้ทำงานกับข้อมูลแบบอาร์เรย์ (array) ได้รวดเร็ว และรองรับการคำนวณแบบเวกเตอร์ (vectorization) ซึ่งเป็นพื้นฐานของการประมวลผลข้อมูลจำนวนมาก\n",
        "\n",
        "![numpy_vs_list](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/numpy_vs_list_1768464708033.png?raw=1)\n",
        "\n",
        "**ฟีเจอร์เด็ด: Broadcasting**\n",
        "NumPy ฉลาดพอที่จะคำนวณอาร์เรย์ที่มีขนาดต่างกันได้โดยไม่ต้องวนลูปเอง\n",
        "เช่น เอา `[1, 2, 3]` คูณกับ `2` มันจะกระจายเลข 2 ไปคูณทุกตัวให้อัตโนมัติ (`[2, 4, 6]`)\n",
        "ทำให้โค้ดสั้นและทำงานไวมาก\n",
        "\n",
        "**กรณีใช้งานที่เจอบ่อย**\n",
        "- คำนวณเมทริกซ์/สถิติ (standardization, normalization) ด้วย vectorization แทนการวนลูป Python ช้า ๆ\n",
        "- ตรวจสอบ `arr.shape` และ `arr.dtype` ก่อนคำนวณเสมอเพื่อลด bug จากขนาด/ชนิดข้อมูลไม่ตรง\n",
        "- ใช้ `astype`, `np.where`, `np.nanmean` เพื่อจัดการ type และ missing values ก่อนส่งต่อให้ Pandas หรือ Spark\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d410cfe",
      "metadata": {
        "id": "6d410cfe"
      },
      "outputs": [],
      "source": [
        "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd259e2a",
      "metadata": {
        "id": "fd259e2a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "arr = np.array([1, 2, 3, 4])\n",
        "(arr.mean(), arr.sum(), arr.min(), arr.max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e525a772",
      "metadata": {
        "id": "e525a772"
      },
      "outputs": [],
      "source": [
        "# vectorization: เพิ่ม 10% ให้ทุกค่าในครั้งเดียว\n",
        "x = np.array([10, 20, 30, 40])\n",
        "x * 1.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf74b30e",
      "metadata": {
        "id": "cf74b30e"
      },
      "outputs": [],
      "source": [
        "# สร้างข้อมูลจำลอง (synthetic data) เพื่อทดลอง\n",
        "np.random.seed(42)\n",
        "values = np.random.normal(loc=70, scale=10, size=20)\n",
        "values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16a5654",
      "metadata": {
        "id": "f16a5654"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1aa5bf7",
      "metadata": {
        "id": "f1aa5bf7"
      },
      "source": [
        "### 6.2 Pandas\n",
        "\n",
        "**แนวคิด**\n",
        "Pandas ใช้จัดการข้อมูลเชิงตาราง (เหมือน spreadsheet แต่ทำซ้ำได้) เหมาะกับขั้นตอน ingest/clean/transform ใน pipeline ขนาดย่อม\n",
        "\n",
        "![pandas_dataframe_structure](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/pandas_dataframe_structure_1768464733427.png?raw=1)\n",
        "\n",
        "**โครงสร้างข้อมูล: Series vs DataFrame**\n",
        "- **Series**: ข้อมูล 1 มิติ (เหมือนคอลัมน์เดียวใน Excel หรือ List ที่มี Index)\n",
        "- **DataFrame**: ข้อมูล 2 มิติ (เหมือนตาราง Excel ทั้งแผ่น) ประกอบด้วยหลาย Series มารวมกัน\n",
        "\n",
        "**แนวทางปฏิบัติที่ช่วยให้ทำงานเร็วขึ้น**\n",
        "- ตั้ง dtype และ index ให้ถูกตั้งแต่แรก จะช่วยลดปัญหา memory และการเปรียบเทียบค่าที่ผิดพลาด\n",
        "- ใช้ method chaining เช่น `df.assign(...).query(...).groupby(...)` เพื่อเขียน pipeline อ่านง่ายและทำซ้ำได้\n",
        "- ถ้าข้อมูลใหญ่ ให้ใช้ `read_csv(..., chunksize=...)` หรือบันทึกเป็น Parquet/Feather เพื่ออ่านซ้ำได้ไวและกินพื้นที่น้อย\n",
        "- ตรวจสุขภาพข้อมูลด้วย `df.info()` และ `df.describe()` ก่อนลงมือ transform เพื่อลด surprise ตอนคำนวณ\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74584f63",
      "metadata": {
        "id": "74584f63"
      },
      "outputs": [],
      "source": [
        "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e1f1ca",
      "metadata": {
        "id": "08e1f1ca"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"city\": [\"Bangkok\", \"Chiang Mai\", \"Phuket\", \"Bangkok\"],\n",
        "    \"population_m\": [10.7, 1.2, 0.4, 10.7],\n",
        "    \"visitors_k\": [120, 35, 50, 130],\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e232f422",
      "metadata": {
        "id": "e232f422"
      },
      "outputs": [],
      "source": [
        "# สร้างคอลัมน์ใหม่จากการคำนวณ\n",
        "df[\"visitors_per_million\"] = df[\"visitors_k\"] / df[\"population_m\"]\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "603959d1",
      "metadata": {
        "id": "603959d1"
      },
      "outputs": [],
      "source": [
        "# สรุปข้อมูลด้วย groupby + agg\n",
        "summary = df.groupby(\"city\").agg(\n",
        "    avg_visitors_k=(\"visitors_k\", \"mean\"),\n",
        "    rows=(\"city\", \"count\"),\n",
        ").reset_index()\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f39da68f",
      "metadata": {
        "id": "f39da68f"
      },
      "outputs": [],
      "source": [
        "# ตัวอย่าง missing values และการทำความสะอาด\n",
        "df2 = df.copy()\n",
        "df2.loc[1, \"visitors_k\"] = None\n",
        "\n",
        "df2.isna().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f81bb0b3",
      "metadata": {
        "id": "f81bb0b3"
      },
      "outputs": [],
      "source": [
        "df2[\"visitors_k\"] = df2[\"visitors_k\"].fillna(df2[\"visitors_k\"].mean())\n",
        "df2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd708fd9",
      "metadata": {
        "id": "bd708fd9"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ab5768c",
      "metadata": {
        "id": "6ab5768c"
      },
      "source": [
        "### 6.3 Matplotlib\n",
        "\n",
        "**แนวคิด**\n",
        "Visualization มีเป้าหมายเพื่อสื่อสารแนวโน้ม ความสัมพันธ์ และความผิดปกติของข้อมูล กราฟที่ดีช่วยให้ตรวจสอบและอธิบาย insight ได้ชัดเจน\n",
        "\n",
        "![matplotlib_chart_types](https://github.com/witsarutsarai12-Academic/128-356-Big-Data/blob/main/images/matplotlib_chart_types_1768465212197.png?raw=1)\n",
        "\n",
        "**เคล็ดลับการเลือกกราฟและจัดรูปแบบ**\n",
        "- เริ่มจากคำถาม: เปรียบเทียบ → bar/column, แนวโน้มเวลา → line, การกระจายตัว → histogram/boxplot, ความสัมพันธ์ → scatter\n",
        "- ตั้ง `plt.figure(figsize=(...))` และ `plt.tight_layout()` เมื่อต้องการจัดพื้นที่ป้ายกำกับและทำให้กราฟอ่านง่ายขึ้น\n",
        "- ถ้าต้องการ style/interactive เพิ่มเติม สามารถต่อยอดด้วย Seaborn หรือ Plotly ได้โดยยังใช้โครงสร้างข้อมูล Pandas เดิม\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeaecc53",
      "metadata": {
        "id": "eeaecc53"
      },
      "outputs": [],
      "source": [
        "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da59f447",
      "metadata": {
        "id": "da59f447"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar(df[\"city\"], df[\"visitors_k\"])\n",
        "plt.title(\"Visitors by City\")\n",
        "plt.ylabel(\"Visitors (thousand)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "286286b2",
      "metadata": {
        "id": "286286b2"
      },
      "outputs": [],
      "source": [
        "plt.plot(summary[\"city\"], summary[\"avg_visitors_k\"], marker=\"o\")\n",
        "plt.title(\"Average Visitors by City\")\n",
        "plt.ylabel(\"Avg visitors (thousand)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aaf4d72",
      "metadata": {
        "id": "4aaf4d72"
      },
      "outputs": [],
      "source": [
        "plt.hist(values, bins=8)\n",
        "plt.title(\"Distribution of Simulated Scores\")\n",
        "plt.xlabel(\"Score\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4e92814",
      "metadata": {
        "id": "d4e92814"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a8feaf7",
      "metadata": {
        "id": "5a8feaf7"
      },
      "source": [
        "## Part 7: สรุปท้ายคาบ\n",
        "\n",
        "### สิ่งที่นักศึกษาควรได้วันนี้\n",
        "- เข้าใจภาพรวม Big Data\n",
        "- เห็นบทบาทของ Python\n",
        "- เขียน Python พื้นฐานได้\n",
        "\n",
        "### เตรียมตัวสัปดาห์หน้า\n",
        "- อ่านเรื่อง CSV vs Parquet และลองแปลงไฟล์เล็ก ๆ เป็น Parquet เพื่อสังเกตขนาดไฟล์ที่ลดลง\n",
        "- ฝึกเขียนฟังก์ชันสั้น ๆ สำหรับ clean ข้อมูล (เช่น ตัดช่องว่าง, แปลงประเภท) และทดลองกับ DataFrame ตัวอย่าง\n",
        "- ติดตั้ง/ทดสอบสภาพแวดล้อมล่วงหน้า (Colab หรือ local venv) แล้วลองรันทุก cell ในส่วน Python พื้นฐานให้ครบ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "title": "Big Data Week 1 – Introduction + Python Fundamentals (4 Hours)",
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}